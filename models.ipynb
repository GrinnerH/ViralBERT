{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"o9qcnA6qK27z"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import torch\n","import transformers\n","import plotly.express as px\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n","from fast_ml.model_development import train_valid_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -q -U fast_ml seaborn sklearn emoji"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score, precision_score, recall_score, balanced_accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n","def scores(y_test, y_pred):\n","    cm = confusion_matrix(y_test, y_pred)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","    return {\n","        \"f1 score\": f1_score(y_test, y_pred, average=\"macro\"),\n","        \"precision\": precision_score(y_test, y_pred, average=\"macro\"),\n","        \"recall\": recall_score(y_test, y_pred, average=\"macro\"),\n","        \"accuracy\": balanced_accuracy_score(y_test, y_pred),\n","        \"plot\": disp.plot(),\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["# Load dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path = \".\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reduced_path = os.path.join(path, \"reducedDataset\")\n","tweets_df = pd.read_csv(os.path.join(reduced_path, \"all.csv\"), header=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tweets_df.drop_duplicates(subset=\"text\", inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tweets_df[\"text_len\"] = tweets_df[\"text\"].apply(len)\n","tweets_df[\"verified\"] = tweets_df[\"verified\"].astype(bool)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tweets_df.info()"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Labelling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87U1za80Kond"},"outputs":[],"source":["RT_THRESHOLDS = [0, 1, 20] # virality classes - change to use other thresholds\n","def vir_transform(rt, th=RT_THRESHOLDS):\n","    # take rt number and return virality class\n","    for i, t in enumerate(th):\n","        if rt <= t:\n","            return i\n","    return len(th)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XytGWYFoKf1-"},"outputs":[],"source":["tweets_df[\"virality\"] = tweets_df[\"retweets\"].apply(vir_transform)"]},{"cell_type":"markdown","metadata":{},"source":["Histogram for RT counts in each class"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["counts, bins = np.histogram(tweets_df.virality, bins=len(RT_THRESHOLDS)+1)\n","fig = px.bar(x=[str(i) for i in range(len(RT_THRESHOLDS) + 1)], y=counts, labels={\"x\": \"Virality\", \"y\": \"Count\"},)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Data loader"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Loader():\n","    def __init__(self, features, labels, batch_size=32, target_size=len(RT_THRESHOLDS) + 1):\n","        self.batch_size = batch_size\n","        self.features = features\n","        self.labels = labels\n","        self.batches = len(self.labels) // self.batch_size\n","        self.index = -1\n","        self.target_size = target_size\n","    \n","    def __len__(self):\n","        return self.batches\n","    \n","    def __iter__(self):\n","        self.index = -1\n","        return self\n","    \n","    def _ohe(self, lbls):\n","        ohe = torch.zeros((lbls.size, self.target_size))\n","        ohe[torch.arange(lbls.size), lbls.values] = 1\n","        return ohe\n","\n","    def __next__(self):\n","        self.index += 1\n","        if self.index > self.batches:\n","            raise StopIteration\n","        start = self.index * self.batch_size \n","        end = (self.index + 1) * self.batch_size\n","        return self.features[start:end], self._ohe(self.labels[start:end])"]},{"cell_type":"markdown","metadata":{"id":"7U-6deYu9JNf"},"source":["# Baseline Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XEJ-l3YN9jj5"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","X_train, X_test, y_train, y_test = train_test_split(\n","    scaler.fit_transform(tweets_df[[\"hashtags\", \"mentions\", \"verified\", \"followers\", \"following\", \"text_len\"]]),\n","    tweets_df[[\"virality\"]],\n","    random_state=42,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWiEZp-j-fcI"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression, SGDClassifier\n","from sklearn import tree\n","from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fit(model, X_train, y_train, X_test, y_test):\n","    model.fit(X_train, np.ravel(y_train))\n","    y_pred = model.predict(X_test)\n","    return scores(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{},"source":["Logistic Regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fit(LogisticRegression(solver=\"newton-cg\"), X_train, y_train, X_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["SVM (with SGD)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fit(SGDClassifier(), X_train, y_train, X_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["Decision Tree"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fit(tree.DecisionTreeClassifier(), X_train, y_train, X_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fit(RandomForestClassifier(random_state=0), X_train, y_train, X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"MnULwc9aDAaA"},"source":["# DL Models (ViralBERT and text/numerical baseline)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":165,"status":"ok","timestamp":1644241229890,"user":{"displayName":"Rikaz Rameez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWhjcGWJFkgRqMqlm58OXgE3zybHoDXH7D4caFXQ=s64","userId":"14120230118512499126"},"user_tz":0},"id":"bp2ZxzuwekDg","outputId":"7064ae5f-37f3-4c82-e745-c2f1ce3c30d7"},"outputs":[],"source":["tweets_df.info()"]},{"cell_type":"markdown","metadata":{},"source":["## Data prep"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_feats = [\"text\", \"hashtags\", \"mentions\", \"followers\", \"following\", \"verified\", \"text_len\", ]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":510,"status":"ok","timestamp":1644241231658,"user":{"displayName":"Rikaz Rameez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWhjcGWJFkgRqMqlm58OXgE3zybHoDXH7D4caFXQ=s64","userId":"14120230118512499126"},"user_tz":0},"id":"QJ-SgPrLfBAM","outputId":"d71f25f1-3c53-4f6e-b40c-404d011dbc59"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","df = tweets_df.loc[:, input_feats].dropna()\n","df[\"virality\"] = le.fit_transform(tweets_df[\"virality\"])\n","df = df.sample(frac=1, random_state=42)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","df[input_feats[4:]] = scaler.fit_transform(df[input_feats[4:]])\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ZjHgUvpc400"},"outputs":[],"source":["(train_features, train_labels,\n"," val_features, val_labels,\n"," test_features, test_labels) = train_valid_test_split(df, target = 'virality', train_size=0.8, valid_size=0.1, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9oBvRIZ89cX"},"outputs":[],"source":["train_loader = Loader(train_features, train_labels)\n","val_loader = Loader(val_features, val_labels)\n","test_loader = Loader(test_features, test_labels)"]},{"cell_type":"markdown","metadata":{},"source":["Tokenise text"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def encode(df, tokenizer=tokenizer, inp=\"text\"):\n","    text = df[inp]\n","    inputs = tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=128,\n","            truncation=True,\n","            pad_to_max_length=True,\n","            return_token_type_ids=False,\n","        )\n","    ids = inputs['input_ids']\n","    mask = inputs['attention_mask']\n","    return torch.tensor(ids, dtype=torch.long), torch.tensor(mask, dtype=torch.long)"]},{"cell_type":"markdown","metadata":{},"source":["Loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["w = [len(train_labels[train_labels == i])/len(train_labels) for i in range(len(RT_THRESHOLDS) + 1)]\n","weights = torch.tensor(w, dtype=torch.float).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# From https://github.com/vandit15/Class-balanced-loss-pytorch.git\n","def focal_loss(logits, labels, alpha=weights, gamma=2.0):\n","    \"\"\"Compute the focal loss between `logits` and the ground truth `labels`.\n","    Focal loss = -alpha_t * (1-pt)^gamma * log(pt)\n","    where pt is the probability of being classified to the true class.\n","    pt = p (if true class), otherwise pt = 1 - p. p = sigmoid(logit).\n","    Args:\n","      labels: A float tensor of size [batch, num_classes].\n","      logits: A float tensor of size [batch, num_classes].\n","      alpha: A float tensor of size [batch_size]\n","        specifying per-example weight for balanced cross entropy.\n","      gamma: A float scalar modulating loss from hard and easy examples.\n","    Returns:\n","      focal_loss: A float32 scalar representing normalized total loss.\n","    \"\"\"    \n","    BCLoss = F.binary_cross_entropy_with_logits(input = logits, target = labels,reduction = \"none\")\n","\n","    if gamma == 0.0:\n","        modulator = 1.0\n","    else:\n","        modulator = torch.exp(-gamma * labels * logits - gamma * torch.log(1 + \n","            torch.exp(-1.0 * logits)))\n","\n","    loss = modulator * BCLoss\n","\n","    weighted_loss = alpha * loss\n","    focal_loss = torch.sum(weighted_loss)\n","\n","    focal_loss /= torch.sum(labels)\n","    return focal_loss\n","\n","criterion = focal_loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sm = nn.Softmax()"]},{"cell_type":"markdown","metadata":{},"source":["## Train Val Test functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train(model, arg_function, epoch, print_every=500, inp=\"text\"):\n","    model.train()\n","    losses = []\n","    for i, (inputs, targets) in enumerate(train_loader):\n","        encode_df = inputs.loc[:, [inp]].apply(encode, inp=inp, axis=1, result_type=\"expand\")\n","        ids = torch.stack(tuple(encode_df[0].values), 0).to(device)\n","        masks = torch.stack(tuple(encode_df[1].values), 0).to(device)\n","        kwargs = arg_function(inputs)\n","        outputs = model(ids, masks, **kwargs)\n","        optimizer.zero_grad()\n","        loss = criterion(outputs, targets.to(device))\n","        losses.append(loss.item())\n","        if i % print_every == 0:\n","            print(f'Epoch: {epoch}, i: {i}, Loss:  {torch.mean(torch.tensor(loss)).item()}')\n","            losses = []\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def validate(model, arg_function, inp=\"text\"):\n","    model.eval()\n","    total_loss = []\n","    all_y = []\n","    all_y_pred = []\n","    for x, y in val_loader:\n","        encode_df = x.loc[:, [inp]].apply(encode, inp=inp, axis=1, result_type=\"expand\")\n","        ids = torch.stack(tuple(encode_df[0].values), 0).to(device)\n","        masks = torch.stack(tuple(encode_df[1].values), 0).to(device)\n","        kwargs = arg_function(x)\n","        y_pred = model(ids, masks, **kwargs)\n","        loss = criterion(y_pred, y.to(device))\n","        y_pred = sm(y_pred)\n","        y_pred = torch.zeros(y_pred.shape).to(device).scatter(1, y_pred.argmax(1).unsqueeze(1), 1).cpu().detach().numpy()\n","        y = y.cpu().detach().numpy()\n","        all_y.append(y.argmax(1))\n","        all_y_pred.append(y_pred.argmax(1))\n","        total_loss.append(loss.item())\n","    print(\"validation loss: \", torch.mean(torch.tensor(total_loss)).item())\n","    all_y = np.concatenate(all_y)\n","    all_y_pred = np.concatenate(all_y_pred)\n","    s = scores(all_y, all_y_pred)\n","    print(s)\n","    print(y)\n","    print(y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test(model, arg_function, inp=\"text\"):\n","    model.eval()\n","    all_y = []\n","    all_y_pred = []\n","    for x, y in test_loader:\n","        encode_df = x.loc[:, [inp]].apply(encode, inp=inp, axis=1, result_type=\"expand\")\n","        ids = torch.stack(tuple(encode_df[0].values), 0).to(device)\n","        masks = torch.stack(tuple(encode_df[1].values), 0).to(device)\n","        kwargs = arg_function(x)\n","        y_pred = model(ids, masks, **kwargs)\n","        y_pred = sm(y_pred)\n","        y_pred = torch.zeros(y_pred.shape).to(device).scatter(1, y_pred.argmax(1).unsqueeze(1), 1).cpu().detach().numpy()\n","        y = y.cpu().detach().numpy()\n","        all_y.append(y.argmax(1))\n","        all_y_pred.append(y_pred.argmax(1))\n","    all_y = np.concatenate(all_y)\n","    all_y_pred = np.concatenate(all_y_pred)\n","    s = scores(all_y, all_y_pred)\n","    print(s)"]},{"cell_type":"markdown","metadata":{},"source":["## Numerical features only"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Arch(nn.Module):\n","    def __init__(self):\n","        super(Arch, self).__init__()\n","        self.linear1 = nn.Linear(6, 32)\n","        self.linear2 = nn.Linear(32, 32)\n","        self.classifier = nn.Linear(32, 4)\n","\n","    def forward(self, input_ids, attention_mask, features):\n","        pooler = self.linear1(features)\n","        pooler = torch.nn.Tanh()(pooler)\n","        pooler = self.linear2(pooler)\n","        pooler = torch.nn.Tanh()(pooler)\n","        output = self.classifier(pooler)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = Arch().to(device)\n","optimizer = transformers.AdamW(params=model.parameters(), lr=1e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["arg_func = lambda x: {\"features\": torch.stack(tuple([torch.from_numpy(x[key].values) for key in x.keys()[1:]]), 1).to(device).type(torch.float)}"]},{"cell_type":"markdown","metadata":{},"source":["#### Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for epoch in range(5):\n","    train(model, arg_func, epoch)\n","    validate(model, arg_func)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save(model.state_dict(), \"./models/mlp_num.pt\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = Arch().to(device)\n","model.load_state_dict(torch.load(\"./models/mlp_num.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test(model, arg_func)"]},{"cell_type":"markdown","metadata":{},"source":["## Text features only"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bert = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=True, normalization=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDXWFi5-FdaH"},"outputs":[],"source":["class Arch(nn.Module):\n","    def __init__(self, bert):\n","        super(Arch, self).__init__()\n","        self.bert = bert\n","        self.pre_classifier = nn.Linear(768, 768)\n","        self.dropout = nn.Dropout(0.1)\n","        self.classifier = nn.Linear(768, 4)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output_1 = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.Tanh()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XRnkekddN-Q5"},"outputs":[],"source":["model = Arch(bert).to(device)\n","optimizer = transformers.AdamW(params=model.parameters(), lr=1e-5)"]},{"cell_type":"markdown","metadata":{},"source":["#### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"5al1-TK79lJ_","outputId":"6955059f-959a-4ed2-e56b-0aad39ce59fd"},"outputs":[],"source":["for epoch in range(3):\n","    train(model, lambda x: {}, epoch)\n","    validate(model, lambda x: {})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRs9QbhWwl6z"},"outputs":[],"source":["torch.save(model.state_dict(), \"./models/vb_text.pt\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = Arch(bert).to(device)\n","model.load_state_dict(torch.load(\"./models/vb_text.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test(model, lambda x: {})"]},{"cell_type":"markdown","metadata":{},"source":["## ViralBERT without sentiment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_feats = [ \"text\", \"hashtags\", \"mentions\", \"followers\", \"following\", \"verified\", \"text_len\", ]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = tweets_df.loc[:, input_feats].dropna()\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def combine_feats(x):\n","    return \". \".join([str(val) for val in x.values])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"text\"] = df.apply(combine_feats, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"virality\"] = le.fit_transform(tweets_df[\"virality\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["(train_features, train_labels,\n"," val_features, val_labels,\n"," test_features, test_labels) = train_valid_test_split(df, target = 'virality', train_size=0.8, valid_size=0.1, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_loader = Loader(train_features, train_labels)\n","val_loader = Loader(val_features, val_labels)\n","test_loader = Loader(test_features, test_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bert = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=True, normalization=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Arch(nn.Module):\n","    def __init__(self, bert, classes=len(RT_THRESHOLDS) + 1):\n","        super(Arch, self).__init__()\n","        self.bert = bert\n","        self.pre_classifier = nn.Linear(768, 768)\n","        self.dropout = nn.Dropout(0.1)\n","        self.classifier = nn.Linear(768, classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output_1 = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.Tanh()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = Arch(bert).to(device)\n","optimizer = transformers.AdamW(params=model.parameters(), lr=1e-5)"]},{"cell_type":"markdown","metadata":{},"source":["#### Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for epoch in range(3):\n","    train(model, lambda x: {}, epoch)\n","    validate(model, lambda x: {})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save(model.state_dict(), \"./models/vb_ablation_sent.pt\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = Arch(bert).to(device)\n","model.load_state_dict(torch.load(\"./models/vb_ablation_sent.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test(model, lambda x: {})"]},{"cell_type":"markdown","metadata":{},"source":["## ViralBERT ablation - numerical features "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Arch(nn.Module):\n","    def __init__(self, bert, sentiment_model):\n","        super(Arch, self).__init__()\n","        self.bert = bert\n","        self.sent = sentiment_model\n","        self.pre_classifier = nn.Linear(771, 771)\n","        self.dropout = nn.Dropout(0.1)\n","        self.classifier = nn.Linear(771, 4)\n","\n","    def forward(self, input_ids, attention_mask, sent_input_ids, sent_attention_mask):\n","        output_1 = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state = output_1[0]\n","        sent_output = self.sent(input_ids=sent_input_ids, attention_mask=sent_attention_mask)\n","        pooler = torch.cat((hidden_state[:, 0], sent_output[0]), 1)\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.Tanh()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def combine_feats(x):\n","    return \". \".join([str(val) for val in x.values])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def arg_func(x):\n","    clean_text = [preprocess(t) for t in x[\"text\"].values]\n","    encoded = sent_tokenizer(clean_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","    sent_input_ids = encoded[\"input_ids\"].to(device)\n","    sent_attention_mask = encoded[\"attention_mask\"].to(device)\n","\n","    return {\"sent_input_ids\": sent_input_ids, \"sent_attention_mask\": sent_attention_mask}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess(text):\n","    new_text = []\n","    for t in text.split(\" \"):\n","        t = '@user' if t.startswith('@') and len(t) > 1 else t\n","        t = 'http' if t.startswith('http') else t\n","        new_text.append(t)\n","    return \" \".join(new_text)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_feats = [\"text\", \"hashtags\", \"mentions\", \"followers\", \"following\", \"verified\", \"text_len\"]\n","\n","for i in range(1, len(input_feats)):\n","    print(\"######################################################################\")\n","    print(\"Removing feature:\", input_feats[i])\n","    df = tweets_df.loc[:, input_feats[:i] + input_feats[i+1:]].dropna()\n","    df[\"input\"] = df.apply(combine_feats, axis=1)\n","    df[\"virality\"] = le.fit_transform(tweets_df[\"virality\"])\n","    (train_features, train_labels,\n","    val_features, val_labels,\n","    test_features, test_labels) = train_valid_test_split(df, target = 'virality', train_size=0.8, valid_size=0.1, test_size=0.1, random_state=42)\n","    \n","    train_loader = Loader(train_features, train_labels)\n","    val_loader = Loader(val_features, val_labels)\n","    test_loader = Loader(test_features, test_labels)\n","\n","    bert = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n","    tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=True, normalization=True)\n","    sent_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n","    sent_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n","    model = Arch(bert, sent_model).to(device)\n","    optimizer = transformers.AdamW(params=model.parameters(), lr=1e-5)\n","    model.load_state_dict(torch.load(f\"./models/vb_ablation_{input_feats[i]}.pt\"))\n","    for epoch in range(3):\n","        train(model, arg_func, epoch+1, inp=\"input\")\n","        # validate(model, arg_func, inp=\"input\")\n","    test(model, arg_func, inp=\"input\")\n","\n","    torch.save(model.state_dict(), f\"./models/final/ablation_{input_feats[i]}-grad-focal-3ep-4class.pt\")"]},{"cell_type":"markdown","metadata":{},"source":["## ViralBERT"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_feats = [\"text\", \"hashtags\", \"mentions\", \"followers\", \"following\", \"verified\", \"text_len\", ]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = tweets_df.loc[:, input_feats].dropna()\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def combine_feats(x):\n","    return \". \".join([str(val) for val in x.values])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"input\"] = df.apply(combine_feats, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"virality\"] = le.fit_transform(tweets_df[\"virality\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["(train_features, train_labels,\n"," val_features, val_labels,\n"," test_features, test_labels) = train_valid_test_split(df, target = 'virality', train_size=0.8, valid_size=0.1, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_loader = Loader(train_features, train_labels)\n","val_loader = Loader(val_features, val_labels)\n","test_loader = Loader(test_features, test_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess(text):\n","    new_text = []\n","    for t in text.split(\" \"):\n","        t = '@user' if t.startswith('@') and len(t) > 1 else t\n","        t = 'http' if t.startswith('http') else t\n","        new_text.append(t)\n","    return \" \".join(new_text)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sent_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n","\n","sent_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bert = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=True, normalization=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Arch(nn.Module):\n","    def __init__(self, bert, sentiment_model):\n","        super(Arch, self).__init__()\n","        self.bert = bert\n","        self.sent = sentiment_model\n","        self.pre_classifier = nn.Linear(771, 771)\n","        self.dropout = nn.Dropout(0.1)\n","        self.classifier = nn.Linear(771, 4)\n","\n","    def forward(self, input_ids, attention_mask, sent_input_ids, sent_attention_mask):\n","        output_1 = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state = output_1[0]\n","        sent_output = self.sent(input_ids=sent_input_ids, attention_mask=sent_attention_mask)\n","        pooler = torch.cat((hidden_state[:, 0], sent_output[0]), 1)\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.Tanh()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = Arch(bert, sent_model).to(device)\n","optimizer = transformers.AdamW(params=model.parameters(), lr=1e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def arg_func(x):\n","    clean_text = [preprocess(t) for t in x[\"text\"].values]\n","    encoded = sent_tokenizer(clean_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","    sent_input_ids = encoded[\"input_ids\"].to(device)\n","    sent_attention_mask = encoded[\"attention_mask\"].to(device)\n","\n","    return {\"sent_input_ids\": sent_input_ids, \"sent_attention_mask\": sent_attention_mask}"]},{"cell_type":"markdown","metadata":{},"source":["#### Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for epoch in range(3):\n","    train(model, arg_func, epoch, inp=\"input\")\n","    validate(model, arg_func, inp=\"input\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save(model.state_dict(), \"./models/vb.pt\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = Arch(bert, sent_model).to(device)\n","model.load_state_dict(torch.load(\"./models/vb.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test(model, arg_func, inp=\"input\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMrBk7BExZFy3T6TvUm9iay","collapsed_sections":["xTqw7QeP4SPL","Yvlvjw7_oHAv","1P7PFvNXoJqg","lLLBHINsuPRY","w-m7ZJE-X2_R","7U-6deYu9JNf","oAlUiX2Uf3wh"],"name":"models.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":0}
